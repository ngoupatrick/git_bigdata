- install vm (22.04.5)
	lsb_release -a
		cat /etc/os-release

- ubuntu cmd:
	apt-cache search <keyword>
		apt-cache show <package-name> -> package details
	apt list --installed
	apt list --upgradable
		snap list

- check sshd:
	sudo systemctl status sshd
		sudo systemctl restart ssh.service
	install: sudo apt install openssh-client openssh-server -y

- keys:
	genarate key on client:
		ssh-keygen -f [path_to_file] -t [ecdsa, rsa, dsa] -b 4096
	copy generated public key to remote user (remote host)
		ssh-copy-id [-i path_pub_key] [user]@[remote_host]
	ssh connexion:
		ssh -i path_private_id_rsa [user]@[remote_host]

- install java:
	11: sudo apt install openjdk-11-jre-headless -y
		sudo apt install openjdk-11-jdk -y
		sudo apt install default-jre -y
	17: sudo apt install openjdk-17-jre-headless -y

	check java:
		java --version
		javac --version
		which sshd|ssh|java
		sudo update-alternatives --config java

- install kafka
	url:
		https://kafka.apache.org/quickstart
		https://hevodata.com/blog/how-to-install-kafka-on-ubuntu/

	wget https://dlcdn.apache.org/kafka/4.0.0/kafka_2.13-4.0.0.tgz
	tar -xzf kafka_2.13-4.0.0.tgz
	mv kafka_2.13-4.0.0 kafka
	cd kafka

	Generate a Cluster UUID
		KAFKA_CLUSTER_ID="$(bin/kafka-storage.sh random-uuid)"
			KAFKA_CLUSTER_ID=YhrKEFNbTiCNn6cDiyruFw
	Format Log Directories:
		mkdir -p ~/data/files
		create folders ~/data/zookeeper/data,log; ~/data/kafka/data,log
		change log and data path in config/server.properties (dataDir=~/data/zookeeper/data
dataLogDir=~/data/zookeeper/log, log.dirs|log.dir=~/data/kafka/log)
		bin/kafka-storage.sh format --standalone -t $KAFKA_CLUSTER_ID -c config/server.properties
	Start the Kafka Server
		bin/kafka-server-start.sh config/server.properties
		bin/kafka-server-stop.sh config/server.properties
			[nohup ./bin/zookeeper-server-start.sh ./config/zookeeper.properties &]
			nohup bin/kafka-server-start.sh config/server.properties &

	create topic:
		bin/kafka-topics.sh --create --topic topic-test --bootstrap-server localhost:9092 [ --replication-factor 1 --partitions 1 --config cleanup.policy=delete --config delete.retention.ms=60000]
	describe:
		bin/kafka-topics.sh --describe --topic topic-test --bootstrap-server localhost:9092
	list:
		bin/kafka-topics.sh --list --bootstrap-server localhost:9092
	write:
		bin/kafka-console-producer.sh --topic topic-test --bootstrap-server localhost:9092
	read:
		bin/kafka-console-consumer.sh --topic topic-test --from-beginning --bootstrap-server localhost:9092
	delete a topic:
    	bin/kafka-topics.sh --bootstrap-server localhost:9092 --delete --topic topic-test

	read data from file
		set jar:
			echo "plugin.path=libs/connect-file-4.0.0.jar" >> config/connect-standalone.properties
		start connector:
			bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-source.properties config/connect-file-sink.properties
		start consumer (cmd and file):
			bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic connect-test --from-beginning
			more (tail -f) test.sink.txt
		write in file (look in consumer output):
			echo -e "foo\nbar" > test.txt
			echo "Another line" >> test.txt

	read & write mysql (debezium & jdbc):
		read:
			https://medium.com/@kayshowz069/change-data-capture-with-debezium-and-kafka-620f3ed4107a
			install mysql-server:
				sudo apt-get install mysql-server -y

			connect:
				sudo mysql -u root -p

			create db and table:
				create database test_db;
				use test_db;
				create table test_table(id int auto_increment primary key, val varchar(10));

			Create user user_mysql with password ‘passer’:
				CREATE USER 'user_mysql'@'localhost' IDENTIFIED BY 'passer';
				CREATE USER 'user_mysql'@'%' IDENTIFIED BY 'passer';

				GRANT SELECT, RELOAD, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'user_mysql'@'localhost';
				GRANT SELECT, RELOAD, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'user_mysql'@'%';
				
					GRANT ALL PRIVILEGES ON *.* TO user_mysql@’%’ IDENTIFIED BY ‘passer’;					
					
				FLUSH PRIVILEGES;

			Check Binary Logging Status with the following commands (ON|OFF):
				SHOW variables LIKE'log_bin';
					SELECT variable_value as "BINARY LOGGING STATUS (log-bin) ::" FROM performance_schema.global_variables WHERE variable_name='log_bin';

			change bin log if OFF:
				option1: SET @@binlog_rows_query_log_events=ON; #If the query result is OFF, then you can enable it.
				option 2:
					edit the MySQL configuration file:
						sudo nano /etc/mysql/mysql.conf.d/mysqld.cnf

[mysqld]

# Set bind address

bind-address = 0.0.0.0
port = 3306
mysqlx-bind-address = 127.0.0.1

# example 1 (if bin log if OFF)

log_bin = ON
log-bin = mysql-bin
binlog_row_image = FULL
binlog-format = ROW
binlog_rows_query_log_events = ON
expire_logs_days = 90
gtid_mode = ON
enforce_gtid_consistency = ON
performance_schema=ON


# Example 2 (if bin log if OFF)

server-id         = 223344 # Querying variable is called server_id, e.g. SELECT @@server_id; || SELECT variable_value FROM information_schema.global_variables WHERE variable_name='server_id';
log_bin                     = mysql-bin
binlog_format               = ROW
binlog_row_image            = FULL
binlog_expire_logs_seconds  = 864000
binlog_rows_query_log_events=ON



			Validating binlog row value options:
				mysql> show global variables where variable_name = 'binlog_row_value_options';
				this variable must be set to a value other than PARTIAL_JSON.
					set @@global.binlog_row_value_options="" ;

			look at some variables:
				mysql> show binary logs;
				mysql> show variables like '%bin%';

			restart mysql:
				sudo service mysql restart

			Setting Up the Debezium MySQL Connector:
				mkdir -p kafka/plugins
				cd kafka/plugins
				wget https://repo1.maven.org/maven2/io/debezium/debezium-connector-mysql/3.0.6.Final/debezium-connector-mysql-3.0.6.Final-plugin.tar.gz
				tar -xvzf debezium-connector-mysql-3.0.6.Final-plugin.tar.gz
				
				# copy jar from plugins to libs
				cp -Rp debezium-connector-mysql/*.jar ../libs/

				#move all jar files in plugins folder 
				mv debezium-connector-mysql/*.jar .				

			add path to properties files:
				nano kafka/config/connect-standalone.properties
					offset.storage.file.filename=/home/nanpson/data/kafka/data/connect.offsets
					plugin.path=libs/connect-file-4.0.0.jar,plugins/
			
			Edit mysql connector:
				nano kafka/config/connect-debezium-mysql.json


# json
curl -i -X PUT -H "Accept:application/json" \
    -H  "Content-Type:application/json" http://localhost:8083/connectors/source-debezium-mysql-00/config \
    -d '
{
    "name": "test-connector",
    "type": "source",
    "config": {
        "connector.class": "io.debezium.connector.mysql.MySqlConnector",
        "database.hostname": "localhost",
        "database.port": "3306",
        "database.user": "user_mysql",
        "database.password": "passer",
        "database.server.id": "1",
        "topic.prefix": "fullfillment",
        "database.include.list": "test_db",
        "table.include.list":"test_db.test_table",
        "table.whitelist": "test_db.test_table",
        "schema.history.internal.kafka.bootstrap.servers": "localhost:9092",
        "schema.history.internal.kafka.topic": "topic.fullfillment",
        "include.schema.changes": "false",
        "schemas.enable": "true",
        "key.converter": "org.apache.kafka.connect.json.JsonConverter",
        "key.converter.schemas.enable": "true",
        "value.converter": "org.apache.kafka.connect.json.JsonConverter",
        "value.converter.schemas.enable": "true"
    },
    "tasks": [
      {
        "connector": "test-connector",
        "task": 0
      }
    ]
}

'


#other options,  comma-separated
table.exclude.list
table.include.list
column.exclude.list
column.include.list



		start services:
			cd kafka
			start kafka			
			start consumer on topic fullfillment.test_db.test_table
			Start Kafka Connect Service:
				bin/connect-standalone.sh config/connect-standalone.properties config/connect-debezium-mysql.json

			cheat sheet:
				url: https://cheatsheetfactory.geekyhacker.com/kafka/kafka-connect-rest

			#You might check whether or not the connection is runing
				curl -s localhost:8083/ | jq
				curl -s localhost:8083/connector-plugins | jq
		test:
			Login to MySQL To Make Database Changes

		troubleshoot:
			https://rmoff.net/2019/10/23/debezium-mysql-v8-public-key-retrieval-is-not-allowed/
			https://medium.com/@a.tambakouzadeh/checklist-to-troubleshoot-kafka-connect-issues-using-debezium-platform-for-cdc-and-mysql-data-b4d517d152a4
			
		just capture payload:
			edit connect-debezium-mysql.properties and connect-standalone.properties file

key.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=false
value.converter=org.apache.kafka.connect.json.JsonConverter
value.converter.schemas.enable=false
schemas.enable=false

# SINK
urls:
	https://medium.com/@alexander.murylev/kafka-connect-debezium-mysql-source-sink-replication-pipeline-fb4d7e9df790
	https://debezium.io/documentation/reference/stable/connectors/jdbc.html#jdbc-deployment

vi connect-standalone.properties

## ADD BY ME
key.converter.schemas.enable=true
value.converter.schemas.enable=true
internal.key.converter.schemas.enable=true
internal.value.converter.schemas.enable=true
internal.key.converter=org.apache.kafka.connect.json.JsonConverter
internal.value.converter=org.apache.kafka.connect.json.JsonConverter
key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter


cd plugins
wget https://repo1.maven.org/maven2/io/debezium/debezium-connector-jdbc/3.0.6.Final/debezium-connector-jdbc-3.0.6.Final-plugin.tar.gz

tar -xvzf debezium-connector-mysql-3.0.6.Final-plugin.tar.gz

# copy jar from plugins to libs
cp -Rp debezium-connector-jdbc/*.jar ../libs/

#move all jar files in plugins folder 
mv debezium-connector-jdbc/*.jar .

# copy jar from plugins to libs
cp -Rp *.jar ../libs/

# restart kafka

#Start Kafka Connect Service:
bin/connect-standalone.sh config/connect-standalone.properties

#You might check whether or not the connection is runing
curl -s localhost:8083/ | jq
curl -s localhost:8083/connector-plugins | jq


nano conf/connect-debezium-mysql-sink.json

{
    "name": "mysql-sink-connector",  
    "config": {
        "heartbeat.interval.ms": "3000",                                                            
        "autoReconnect":"true",
        "connector.class": "io.debezium.connector.jdbc.JdbcSinkConnector",  
        "tasks.max": "5",  
        "connection.url":"jdbc:mysql://localhost:3306/test_db_sink",   # specify sink DB
        "connection.username": "user_mysql",  
        "connection.password": "passer",  
        "insert.mode": "upsert",  
        "delete.enabled": "true",  
        "primary.key.mode": "record_key",  
        "schema.evolution": "basic",  
        "database.time_zone": "UTC",
        "auto.evolve": "true",
        "quote.identifiers":"true",
        "auto.create":"true",                                 # auto create tables
        "value.converter.schemas.enable":"true",              # auto reflect schema changes
        "value.converter":"org.apache.kafka.connect.json.JsonConverter",
        "table.name.format": "${topic}",
        "topics.regex":"fullfillment.test_db.*",  # topics regexp to replicate
        "pk.mode" :"kafka"
  }
}



- start kafka
- clean all topics
- update conf/connect-standalone.properties
- update conf/connect-debezium-mysql.json
- update conf/connect-debezium-mysql-sink.json
- update jar
- stop kafka
- delete offsets file (/home/nanpson/data/kafka/data/connect.offsets, mv connect.offsets connect.offsets.bak3)
- create database test_db_sink
- start kafka
- bin/connect-standalone.sh config/connect-standalone.properties config/connect-debezium-mysql.json conf/connect-debezium-mysql-sink.json


####### Trash #####



		https://github.com/wushujames/kafka-mysql-connector/tree/master
			https://github.com/wushujames/kafka-connect-jdbc/tree/master
			https://medium.com/@alexander.murylev/kafka-connect-debezium-mysql-source-sink-replication-pipeline-fb4d7e9df790
		https://debezium.io/documentation/reference/stable/connectors/mysql.html#setting-up-mysql
			https://debezium.io/documentation/reference/stable/connectors/jdbc.html#jdbc-deployment
		troubleshoot:
			https://groups.google.com/g/debezium/c/rLhOD6dZkhE
			https://karla.tistory.com/11

		https://hevodata.com/learn/mysql-kafka-connector/
		https://debezium.io/documentation/reference/stable/connectors/mysql.html
		https://github.com/confluentinc/demo-scene/tree/master/livestreams/july-15
		https://github.com/confluentinc/demo-scene/tree/master/connect-jdbc

- install hadoop
	url:
		https://shape.host/resources/guide-dinstallation-dapache-hadoop-pour-les-utilisateurs-dubuntu-22-04

- minio:
	url:
		https://www.atlantic.net/dedicated-server-hosting/how-to-deploy-minio-on-ubuntu-22-04-an-open-source-object-storage-application/




rm -rf angus-activation-2.0.0.jar
rm -rf antlr4-runtime-4.10.1.jar
rm -rf byte-buddy-1.14.11.jar
rm -rf c3p0-0.9.5.5.jar
rm -rf caffeine-2.9.3.jar
rm -rf classmate-1.5.1.jar
rm -rf debezium-api-3.0.6.Final.jar
rm -rf debezium-connector-binlog-3.0.6.Final.jar
rm -rf debezium-connector-jdbc-3.0.6.Final.jar
rm -rf debezium-connector-mysql-3.0.6.Final.jar
rm -rf debezium-core-3.0.6.Final.jar
rm -rf debezium-ddl-parser-3.0.6.Final.jar
rm -rf debezium-sink-3.0.6.Final.jar
rm -rf debezium-storage-file-3.0.6.Final.jar
rm -rf debezium-storage-kafka-3.0.6.Final.jar
rm -rf error_prone_annotations-2.10.0.jar
rm -rf hibernate-c3p0-6.4.8.Final.jar
rm -rf hibernate-commons-annotations-6.0.6.Final.jar
rm -rf hibernate-core-6.4.8.Final.jar
rm -rf istack-commons-runtime-4.1.1.jar
rm -rf jakarta.activation-api-2.1.0.jar
rm -rf jakarta.inject-api-2.0.1.jar
rm -rf jakarta.persistence-api-3.1.0.jar
rm -rf jakarta.transaction-api-2.0.1.jar
rm -rf jakarta.xml.bind-api-4.0.0.jar
rm -rf jandex-3.1.2.jar
rm -rf jaxb-core-4.0.2.jar
rm -rf jaxb-runtime-4.0.2.jar
rm -rf jboss-logging-3.5.0.Final.jar
rm -rf jcl-over-slf4j-1.7.36.jar
rm -rf jna-5.12.1.jar
rm -rf jna-platform-5.12.1.jar
rm -rf mariadb-java-client-3.2.0.jar
rm -rf mchange-commons-java-0.2.19.jar
rm -rf mssql-jdbc-12.4.2.jre8.jar
rm -rf mysql-binlog-connector-java-0.40.2.jar
rm -rf mysql-connector-j-9.1.0.jar
rm -rf ojdbc11-21.15.0.0.jar
rm -rf postgresql-42.6.1.jar
rm -rf txw2-4.0.2.jar
rm -rf waffle-jna-3.2.0.jar
rm -rf zstd-jni-1.5.6-4.jar




rm -rf angus-activation-2.0.0.jar
rm -rf antlr4-runtime-4.10.1.jar
rm -rf byte-buddy-1.14.11.jar
rm -rf c3p0-0.9.5.5.jar
rm -rf caffeine-2.9.3.jar
rm -rf classmate-1.5.1.jar
rm -rf debezium-api-3.0.6.Final.jar
rm -rf debezium-connector-jdbc-3.0.6.Final.jar
rm -rf debezium-core-3.0.6.Final.jar
rm -rf debezium-sink-3.0.6.Final.jar
rm -rf error_prone_annotations-2.10.0.jar
rm -rf hibernate-c3p0-6.4.8.Final.jar
rm -rf hibernate-commons-annotations-6.0.6.Final.jar
rm -rf hibernate-core-6.4.8.Final.jar
rm -rf istack-commons-runtime-4.1.1.jar
rm -rf jakarta.activation-api-2.1.0.jar
rm -rf jakarta.inject-api-2.0.1.jar
rm -rf jakarta.persistence-api-3.1.0.jar
rm -rf jakarta.transaction-api-2.0.1.jar
rm -rf jakarta.xml.bind-api-4.0.0.jar
rm -rf jandex-3.1.2.jar
rm -rf jaxb-core-4.0.2.jar
rm -rf jaxb-runtime-4.0.2.jar
rm -rf jboss-logging-3.5.0.Final.jar
rm -rf jcl-over-slf4j-1.7.36.jar
rm -rf jna-5.12.1.jar
rm -rf jna-platform-5.12.1.jar
rm -rf mariadb-java-client-3.2.0.jar
rm -rf mchange-commons-java-0.2.19.jar
rm -rf mssql-jdbc-12.4.2.jre8.jar
rm -rf mysql-connector-j-9.1.0.jar
rm -rf ojdbc11-21.15.0.0.jar
rm -rf postgresql-42.6.1.jar
rm -rf txw2-4.0.2.jar
rm -rf waffle-jna-3.2.0.jar



rm -rf CHANGELOG.md
rm -rf CONTRIBUTE.md
rm -rf COPYRIGHT.txt
rm -rf LICENSE-3rd-PARTIES.txt
rm -rf LICENSE.txt
rm -rf README.md
rm -rf README_JA.md
rm -rf README_KO.md
rm -rf README_ZH.md
rm -rf debezium-core-3.0.6.Final.jar
rm -rf debezium-api-3.0.6.Final.jar
rm -rf debezium-connector-binlog-3.0.6.Final.jar
rm -rf debezium-storage-kafka-3.0.6.Final.jar
rm -rf debezium-storage-file-3.0.6.Final.jar
rm -rf debezium-ddl-parser-3.0.6.Final.jar
rm -rf antlr4-runtime-4.10.1.jar
rm -rf mysql-binlog-connector-java-0.40.2.jar
rm -rf zstd-jni-1.5.6-4.jar
rm -rf mysql-connector-j-9.1.0.jar
rm -rf debezium-connector-mysql-3.0.6.Final.jar





#####
debezium example:
	https://github.com/ayyoubmaul/cdc-debezium-kafka/tree/main
	https://github.com/debezium/debezium-examples?tab=readme-ov-file
		https://github.com/debezium/debezium-examples/tree/main/end-to-end-demo
	https://github.com/trannhatnguyen2/streaming_data_processing/tree/main


